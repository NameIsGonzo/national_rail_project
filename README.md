<h1 align='center'>
ğŸš‚ RailScope 
</h1>
<h2 align='center'>
ğŸš¦ Real-Time Performance Analysis for UK National Rail ğŸ›¤ï¸
</h2>

## ğŸ“ Project description:

The RTPPM API provides real-time data on the Public Performance Measure (PPM), including metrics such as on-time trains, late trains, canceled/very late trains, and an indicator of overall performance. The data from this API will be transformed and processed for non-technical users.

The RTPPM API data is expected to arrive every 60 seconds

The dashboard will display key performance indicators such as on-time percentage, cancellations, and delays.

The dashboard will be designed for use by both operations managers and other stakeholders who need to monitor the performance of the National Rail system, as well as the general public. By making the dashboard publicly available, anyone can monitor the performance of the National Rail system without having to study the technical aspects of the underlying APIs.

## ğŸ› ï¸ Pre requisites:

### ğŸ“¡ Network Rail Account
First, register for an account by visiting https://publicdatafeeds.networkrail.co.uk/. 
<br> 

You will receive a confirmation email ğŸ“§. Follow the instructions to log in and change your password. When your account is active, you can connect to the service. Your account may be in one of three states - the system will send you an email when your account is activated and able to access feeds.


### ğŸš€ Apache Spark - PySpark
To get started with this project on your local machine, you'll need to have Apache Spark installed. If you're not sure how to do that, don't worry - DataTalksClub has put together some great tutorials that cover different operating systems:

ğŸ§ [Linux](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_5_batch_processing/setup/linux.md)

ğŸ [MacOS](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_5_batch_processing/setup/macos.md)

ğŸ–¥ï¸ [Windows](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_5_batch_processing/setup/windows.md)

Just pick the one that's right for you and follow the instructions.

Oh, and one more thing - we'll be using PySpark, which is the Python API for Spark. If you don't already have PySpark installed and configured, no worries - [DataTalksClub](https://github.com/DataTalksClub) has you covered there too:

ğŸ [PySpark](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_5_batch_processing/setup/pyspark.md)


Big thanks to [DataTalksClub](https://github.com/DataTalksClub) for creating these helpful tutorials! ğŸ‘




